{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f912cde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for feat in self.features[:-1]:\n",
    "            x = nn.relu(nn.Dense(feat)(x))\n",
    "        x = nn.Dense(self.features[-1])(x)\n",
    "        return x\n",
    "\n",
    "# 모델 선언\n",
    "model = MLP([12, 8, 4])\n",
    "\n",
    "# 데이터 준비\n",
    "batch = jnp.ones((32, 10))\n",
    "\n",
    "# 모델 준비\n",
    "variables = model.init(jax.random.PRNGKey(0), batch)\n",
    "\n",
    "# 모델에 데이터 적용\n",
    "output = model.apply(variables, batch)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38bcf94",
   "metadata": {},
   "source": [
    "https://wandb.ai/wandb_fc/tips/reports/How-To-Create-an-Image-Classification-Model-in-JAX-Flax--VmlldzoyMjA0Mjk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec670c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinsihun/anaconda3/envs/jax/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp               # JAX NumPy\n",
    "\n",
    "from flax import linen as nn          # The Linen API\n",
    "from flax.training import train_state\n",
    "import optax                          # The Optax gradient processing and optimization library\n",
    "\n",
    "import numpy as np                    # Ordinary NumPy\n",
    "import tensorflow_datasets as tfds    # TFDS for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02a45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    n_classes: int\n",
    "\n",
    "    @nn.compact\n",
    "    # Provide a constructor to register a new parameter \n",
    "    # and return its initial value\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1)) # Flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)    # There are 10 classes in MNIST\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1bd27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def cross_entropy_loss(logits, label):\n",
    "    return -logits[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1890bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits, jax.nn.one_hot(labels, num_classes=10)))\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97ad6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    ds_builder = tfds.builder('mnist')\n",
    "    ds_builder.download_and_prepare()\n",
    "    # Split into training/test sets\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    # Convert to floating-points\n",
    "    train_ds['image'] = jnp.float32(train_ds['image']) / 255.0\n",
    "    test_ds['image'] = jnp.float32(test_ds['image']) / 255.0\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91903180",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = CNN(n_classes=10).apply({'params': params}, batch['image'])\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(\n",
    "            logits=logits, \n",
    "            labels=jax.nn.one_hot(batch['label'], num_classes=10)))\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits, batch['label'])\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "837a7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    logits = CNN(n_classes=10).apply({'params': params}, batch['image'])\n",
    "    return compute_metrics(logits, batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62aec2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    perms = jax.random.permutation(rng, len(train_ds['image']))\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # Skip an incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    batch_metrics = []\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    training_batch_metrics = jax.device_get(batch_metrics)\n",
    "    training_epoch_metrics = {\n",
    "        k: np.mean([metrics[k] for metrics in training_batch_metrics])\n",
    "        for k in training_batch_metrics[0]}\n",
    "\n",
    "    print('Training - epoch: %d, loss: %.4f, accuracy: %.2f' % (epoch, training_epoch_metrics['loss'], training_epoch_metrics['accuracy'] * 100))\n",
    "\n",
    "    return state, training_epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4ccec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_ds):\n",
    "    metrics = eval_step(model, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    eval_summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return eval_summary['loss'], eval_summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e27a7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89d6df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55bc6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(n_classes = 10)\n",
    "params = cnn.init(init_rng, jnp.ones([1, 28, 28, 1]))['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecabb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nesterov_momentum = 0.9\n",
    "learning_rate = 0.001\n",
    "tx = optax.sgd(learning_rate=learning_rate, nesterov=nesterov_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "054f755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = train_state.TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ecb08879",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63628e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - epoch: 1, loss: 1.7937, accuracy: 62.74\n",
      "Testing - epoch: 1, loss: 0.93, accuracy: 82.31\n",
      "Training - epoch: 2, loss: 0.6111, accuracy: 85.10\n",
      "Testing - epoch: 2, loss: 0.44, accuracy: 88.47\n",
      "Training - epoch: 3, loss: 0.4127, accuracy: 88.41\n",
      "Testing - epoch: 3, loss: 0.36, accuracy: 89.90\n",
      "Training - epoch: 4, loss: 0.3597, accuracy: 89.69\n",
      "Testing - epoch: 4, loss: 0.32, accuracy: 90.80\n",
      "Training - epoch: 5, loss: 0.3279, accuracy: 90.49\n",
      "Testing - epoch: 5, loss: 0.30, accuracy: 91.56\n",
      "Training - epoch: 6, loss: 0.3046, accuracy: 91.19\n",
      "Testing - epoch: 6, loss: 0.28, accuracy: 91.98\n",
      "Training - epoch: 7, loss: 0.2851, accuracy: 91.72\n",
      "Testing - epoch: 7, loss: 0.26, accuracy: 92.24\n",
      "Training - epoch: 8, loss: 0.2679, accuracy: 92.16\n",
      "Testing - epoch: 8, loss: 0.24, accuracy: 92.89\n",
      "Training - epoch: 9, loss: 0.2520, accuracy: 92.73\n",
      "Testing - epoch: 9, loss: 0.23, accuracy: 93.18\n",
      "Training - epoch: 10, loss: 0.2383, accuracy: 92.99\n",
      "Testing - epoch: 10, loss: 0.22, accuracy: 93.54\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    # Evaluate on the test set after each training epoch\n",
    "    test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "    print('Testing - epoch: %d, loss: %.2f, accuracy: %.2f' % (epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805b130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
