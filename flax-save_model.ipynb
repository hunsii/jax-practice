{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68c629c",
   "metadata": {},
   "source": [
    "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial5/Inception_ResNet_DenseNet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c58d22c",
   "metadata": {},
   "source": [
    "https://flax.readthedocs.io/en/latest/getting_started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2e805",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Any\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a603969",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def mapping(n, inverse=False):\n",
    "    mapping_dict = {'피스': 0, '터짐': 1, '곰팡이': 2, '들뜸': 3, '오염': 4, '창틀,문틀수정': 5, '면불량': 6, '걸레받이수정': 7, '몰딩수정': 8, '오타공': 9, '석고수정': 10, '이음부불량': 11, '꼬임': 12, '울음': 13, '틈새과다': 14, '훼손': 15, '가구수정': 16, '반점': 17, '녹오염': 18}\n",
    "    inverse_mapping = {v: k for k, v in mapping_dict.items()}\n",
    "    if inverse:\n",
    "        return inverse_mapping[n]\n",
    "    return mapping_dict[n]\n",
    "\n",
    "def imread_and_resize(img_path, size = (224, 224)):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((224, 224))\n",
    "    \n",
    "    return image\n",
    "\n",
    "def get_datasets(batch_size = 32):\n",
    "    img_path_list = glob.glob(\"../dataset/train/*/*.png\")\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for path in tqdm(img_path_list):\n",
    "        img_list.append(imread_and_resize(path))\n",
    "        label_list.append(mapping(path.split('/')[3]))\n",
    "    images = jnp.stack([jnp.array(img) for img in img_list])\n",
    "    labels = jnp.array(label_list)\n",
    "    images.shape, labels.shape\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    print(x_train.shape, y_train.shape)\n",
    "\n",
    "    train_ds = []\n",
    "    for i in range(np.ceil(x_train.shape[0] / 32).astype(np.int8)):\n",
    "        batch_start = i * 32\n",
    "        batch_end = (i+1) * 32\n",
    "        sub_dict = {\n",
    "            'image': x_train[batch_start:batch_end], \n",
    "            'label': y_train[batch_start:batch_end], \n",
    "        }\n",
    "        train_ds.append(sub_dict)\n",
    "\n",
    "    test_ds = []\n",
    "    for i in range(np.ceil(x_test.shape[0] / 32).astype(np.int8)):\n",
    "        batch_start = i * 32\n",
    "        batch_end = (i+1) * 32\n",
    "        sub_dict = {\n",
    "            'image': x_train[batch_start:batch_end], \n",
    "            'label': y_train[batch_start:batch_end], \n",
    "        }\n",
    "        test_ds.append(sub_dict)\n",
    "    print(len(train_ds), len(test_ds))\n",
    "    return train_ds, test_ds\n",
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b199fb",
   "metadata": {},
   "source": [
    "# 3. Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3814092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn  # Linen API\n",
    "\n",
    "# from models import create_efficientnet_v2\n",
    "# model = create_efficientnet_v2('s', num_classes = 19)\n",
    "\n",
    "\"\"\"\n",
    "Efficientnet_b0 from https://github.com/rwightman/efficientnet-jax\n",
    "to use this.\n",
    "1. git clone repository\n",
    "2. copy jeffnet directory to here.\n",
    "\"\"\"\n",
    "from jeffnet.linen import create_model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model, variables = create_model('pt_efficientnet_b0', pretrained=True, rng=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48870dd",
   "metadata": {},
   "source": [
    "## View model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp  # JAX NumPy\n",
    "\n",
    "\n",
    "# print(model.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 224, 224, 3)), training=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68f0f4",
   "metadata": {},
   "source": [
    "# 4. Create a TrainState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clu import metrics\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "from flax import struct                # Flax dataclasses\n",
    "import optax                           # Common loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab01d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7750da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    batch_stats: Any\n",
    "\n",
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "    \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "    vars_in = module.init(rng, jnp.ones([1, 224, 224, 3]), training=False) # initialize parameters by passing a template image\n",
    "#     parm\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply, \n",
    "        params=vars_in['params'], \n",
    "        batch_stats=vars_in['batch_stats'], \n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469be2e",
   "metadata": {},
   "source": [
    "# 5. Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: TrainState, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits, updates = state.apply_fn(\n",
    "            {'params': params, 'batch_stats': state.batch_stats},\n",
    "            x=batch['image'], \n",
    "            training=True, \n",
    "            mutable=['batch_stats']\n",
    "        )\n",
    "        \n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits=logits, labels=batch['label']).mean()\n",
    "        return loss, (logits, updates)\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, (logits, updates)), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    state = state.replace(batch_stats=updates['batch_stats'])\n",
    "    metrics = {\n",
    "        'train_loss': loss,\n",
    "        'train_accuracy': jnp.mean(jnp.argmax(logits, -1) == batch['label']),\n",
    "    }\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(state: TrainState, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    logits = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        x=batch['image'], \n",
    "        training=False)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch['label']).mean()\n",
    "    metrics = {\n",
    "        'test_loss': loss,\n",
    "        'test_accuracy': jnp.mean(jnp.argmax(logits, -1) == batch['label']),\n",
    "    }\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a1f92",
   "metadata": {},
   "source": [
    "# 6. Metric computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    logits = module.apply(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats}, \n",
    "        batch['image'], \n",
    "        training=False)\n",
    "\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch['label']).mean()\n",
    "    metric_updates = state.metrics.single_from_model_output(\n",
    "        logits=logits, labels=batch['label'], loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6196b",
   "metadata": {},
   "source": [
    "# 7. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# train_ds, test_ds = get_datasets(num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ba561",
   "metadata": {},
   "source": [
    "# 8. Seed randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18455ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(0)\n",
    "init_rng  = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afcb49",
   "metadata": {},
   "source": [
    "# 9. Initialize the TrainState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(model, init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0dc9b",
   "metadata": {},
   "source": [
    "# 10. Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'test_loss': [],\n",
    "    'test_accuracy': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2ee24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Run optimization steps over training batches and compute batch metrics\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for step, batch in enumerate(train_ds):\n",
    "        state, loss_metrics = train_step(state, batch) # get updated train state (which contains the updated parameters)\n",
    "        loss_list.append(loss_metrics['train_loss'])\n",
    "        acc_list.append(loss_metrics['train_accuracy'])\n",
    "    metrics_history['train_loss'].append(np.mean(loss_list))\n",
    "    metrics_history['train_accuracy'].append(np.mean(acc_list))\n",
    "\n",
    "    \n",
    "    # Test part\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for step, batch in enumerate(test_ds):\n",
    "        _, loss_metrics = eval_step(state, batch)\n",
    "        loss_list.append(loss_metrics['test_loss'])\n",
    "        acc_list.append(loss_metrics['test_accuracy'])\n",
    "    metrics_history['test_loss'].append(np.mean(loss_list))\n",
    "    metrics_history['test_accuracy'].append(np.mean(acc_list))\n",
    "        \n",
    "    print(f\"epoch: {epoch +1}\")\n",
    "    for key, value in metrics_history.items():\n",
    "        print(f'{key:>20} | {value[-1]:<.8}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b480b8",
   "metadata": {},
   "source": [
    "# 11. Visualize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Visualization\n",
    "\n",
    "# Plot loss and accuracy in subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.set_title('Loss')\n",
    "ax2.set_title('Accuracy')\n",
    "for dataset in ('train','test'):\n",
    "    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
    "    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538acb0e",
   "metadata": {},
   "source": [
    "# 12. Perform inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def pred_step(state: TrainState, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    logits = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        x=batch['image'], \n",
    "        training=False)\n",
    "    return jnp.argmax(logits, -1)\n",
    "\n",
    "pred_list = []\n",
    "for step, batch in enumerate(test_ds):\n",
    "    pred = pred_step(state, batch)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "type(pred_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cee49c",
   "metadata": {},
   "source": [
    "# 13. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "ckpt_dir = 'tmp'\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)  # Remove any existing checkpoints from the last notebook run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f72928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle everything together.\n",
    "config = {\n",
    "    'input_shape': (224, 224, 3), \n",
    "    'name': 'efficientent-b0'\n",
    "}\n",
    "test_variable = 1234\n",
    "ckpt = {'state': state, 'config': config, 'test_variable': test_variable}\n",
    "# ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "orbax_checkpointer.save('tmp/orbax/single_save', ckpt, save_args=save_args)\n",
    "\n",
    "os.listdir('tmp/orbax/single_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save('tmp/orbax/single_save', ckpt, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=2, create=True)\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(\n",
    "    'tmp/orbax/managed', orbax_checkpointer, options)\n",
    "\n",
    "# Inside a training loop\n",
    "for step in range(5):\n",
    "    # ... do your training\n",
    "    checkpoint_manager.save(step, ckpt, save_kwargs={'save_args': save_args})\n",
    "\n",
    "os.listdir('tmp/orbax/managed')  # Because max_to_keep=2, only step 3 and 4 are retained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923f26b",
   "metadata": {},
   "source": [
    "# 14. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_state = train_state.TrainState.create(\n",
    "#     apply_fn=model.apply,\n",
    "#     params=jax.tree_map(np.zeros_like, variables['params']),  # values of the tree leaf doesn't matter\n",
    "#     tx=tx,\n",
    "# )\n",
    "# empty_config = {'dimensions': np.array([0, 0]), 'name': ''}\n",
    "target = None\n",
    "state_restored = orbax_checkpointer.restore('tmp/orbax/single_save', item=target)\n",
    "state_restored.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_restored = orbax_checkpointer.restore('tmp/orbax/single_save')\n",
    "state_restored.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = checkpoint_manager.latest_step()  # step = 4\n",
    "print(step)\n",
    "# checkpoint_manager.restore(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ee4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('tmp/orbax/managed')  # Because max_to_keep=2, only step 3 and 4 are retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b8a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
